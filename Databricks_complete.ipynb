{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c3f752e-504d-4e21-95f8-4f24e7294d69",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "#L6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c66e58ac-9fbe-4eec-8f59-6b154a68653f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#dbutils commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9124c4a4-e425-4959-b15c-ee56b4bcce66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\">\n",
       "This module provides various utilities for users to interact with the rest of Databricks.\n",
       "  <h3></h3><b>credentials: DatabricksCredentialUtils</b> -> Utilities for interacting with credentials within notebooks<br /><b>data: DataUtils</b> -> Utilities for understanding and interacting with datasets (EXPERIMENTAL)<br /><b>fs: DbfsUtils</b> -> Manipulates the Databricks filesystem (DBFS) from the console<br /><b>jobs: JobsUtils</b> -> Utilities for leveraging jobs features<br /><b>library: LibraryUtils</b> -> Utilities for session isolated libraries<br /><b>meta: MetaUtils</b> -> Methods to hook into the compiler (EXPERIMENTAL)<br /><b>notebook: NotebookUtils</b> -> Utilities for the control flow of a notebook (EXPERIMENTAL)<br /><b>preview: Preview</b> -> Utilities under preview category<br /><b>secrets: SecretUtils</b> -> Provides utilities for leveraging secrets within notebooks<br /><b>widgets: WidgetsUtils</b> -> Methods to create and get bound value of input widgets inside notebooks<br /><br /></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class = \"ansiout\">\nThis module provides various utilities for users to interact with the rest of Databricks.\n  <h3></h3><b>credentials: DatabricksCredentialUtils</b> -> Utilities for interacting with credentials within notebooks<br /><b>data: DataUtils</b> -> Utilities for understanding and interacting with datasets (EXPERIMENTAL)<br /><b>fs: DbfsUtils</b> -> Manipulates the Databricks filesystem (DBFS) from the console<br /><b>jobs: JobsUtils</b> -> Utilities for leveraging jobs features<br /><b>library: LibraryUtils</b> -> Utilities for session isolated libraries<br /><b>meta: MetaUtils</b> -> Methods to hook into the compiler (EXPERIMENTAL)<br /><b>notebook: NotebookUtils</b> -> Utilities for the control flow of a notebook (EXPERIMENTAL)<br /><b>preview: Preview</b> -> Utilities under preview category<br /><b>secrets: SecretUtils</b> -> Provides utilities for leveraging secrets within notebooks<br /><b>widgets: WidgetsUtils</b> -> Methods to create and get bound value of input widgets inside notebooks<br /><br /></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84f40084-edd8-442c-951e-7995f98ea28d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##dbutils fs commands (file system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c21f3a7-b79f-40d7-89f6-a68275b037f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\n",
       "this package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\n",
       "another FileSystem URI.\n",
       "\n",
       "For more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n",
       "\n",
       "In notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\n",
       "straightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\n",
       "translates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n",
       "    <h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /><h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\nthis package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\nanother FileSystem URI.\n\nFor more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n\nIn notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\nstraightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\ntranslates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n    <h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /><h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70ee652b-d145-44e2-b24c-2a201db73b41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: [FileInfo(path='dbfs:/FileStore/tables/temp/', name='temp/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "# Lists the contents within the path provided\n",
    "dbutils.fs.ls(\"/FileStore/tables/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52eecf99-f679-4a00-8745-02b4f1bc336f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 39 bytes.\nOut[20]: True"
     ]
    }
   ],
   "source": [
    "# Create a file at the path and enter content into it\n",
    "dbutils.fs.put(\"/FileStore/tables/cpdemo.txt\", \"Welcome to Cloudpandith online training\", True)\n",
    "\n",
    "##dbutils.fs.ls(\"/FileStore/tables/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c3c0d1-ab68-4a1c-beea-b8dd4fa3ab04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[35]: [FileInfo(path='dbfs:/FileStore/tables/temp/', name='temp/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "# Remove this cell\n",
    "\n",
    "dbutils.fs.ls(\"/FileStore/tables/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42cc1ad3-5d10-410c-95e5-3878459cc660",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[21]: 'Welcome to Cloudpandith online training'"
     ]
    }
   ],
   "source": [
    "# View the content in the file\n",
    "dbutils.fs.head(\"/FileStore/tables/cpdemo.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8b8fd5d-4bb4-4cb3-b08f-691d14d85564",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[23]: True"
     ]
    }
   ],
   "source": [
    "# Create a folder at the path\n",
    "dbutils.fs.mkdirs(\"/FileStore/tables/input\")\n",
    "dbutils.fs.mkdirs(\"/FileStore/tables/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f3c0a81-95e3-4f02-814c-0819db0441b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[27]: True"
     ]
    }
   ],
   "source": [
    "# Copy a file from source to destination path\n",
    "dbutils.fs.cp(\"/FileStore/tables/cpdemo.txt\", \"/FileStore/tables/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8397728-5786-423b-8dcf-6c6dacafc22c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[28]: True"
     ]
    }
   ],
   "source": [
    "# Move the file from source to destination path\n",
    "dbutils.fs.mv(\"/FileStore/tables/input/cpdemo.txt\", \"/FileStore/tables/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f24abbb8-4f38-4925-a1e3-87b6a6121acd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[34]: True"
     ]
    }
   ],
   "source": [
    "# To remove a file or folder\n",
    "dbutils.fs.rm(\"/FileStore/tables/cpdemo.txt\")\n",
    "\n",
    "# Setting recursively = True, it will delete the files and the folder as well\n",
    "dbutils.fs.rm(\"/FileStore/tables/output\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d6e8ed-228f-4b49-a3a4-fab3bd0f3e28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: [MountInfo(mountPoint='/mnt/dataquaility-data', source='wasbs://dataquaility-data@dbprojectblob0809.blob.core.windows.net', encryptionType=''),\n MountInfo(mountPoint='/databricks-datasets', source='databricks-datasets', encryptionType=''),\n MountInfo(mountPoint='/databricks/mlflow-tracking', source='databricks/mlflow-tracking', encryptionType='sse-s3'),\n MountInfo(mountPoint='/databricks-results', source='databricks-results', encryptionType='sse-s3'),\n MountInfo(mountPoint='/databricks/mlflow-registry', source='databricks/mlflow-registry', encryptionType='sse-s3'),\n MountInfo(mountPoint='/mnt/global', source='wasbs://global@blob0411new.blob.core.windows.net', encryptionType=''),\n MountInfo(mountPoint='/mnt/input', source='wasbs://input@adlsgen201102023.blob.core.windows.net', encryptionType=''),\n MountInfo(mountPoint='/', source='DatabricksRoot', encryptionType='sse-s3')]"
     ]
    }
   ],
   "source": [
    "# Displays all the mount points availiable\n",
    "dbutils.fs.mounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75250459-d3d2-4f64-9378-b7f3f9e4a298",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/global has been unmounted.\nOut[2]: True"
     ]
    }
   ],
   "source": [
    "# To remove a mount point connection\n",
    "dbutils.fs.unmount('/mnt/global')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7fb9f05-77f0-4f50-861b-52276036ceb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##dbutils.secrets (credential security)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc362e4-91c0-4329-b726-20d450830421",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\">\n",
       "Provides utilities for leveraging secrets within notebooks.\n",
       "Databricks documentation for more info.\n",
       "    <h3></h3><b>get(scope: String, key: String): String</b> -> Gets the string representation of a secret value with scope and key<br /><b>getBytes(scope: String, key: String): byte[]</b> -> Gets the bytes representation of a secret value with scope and key<br /><b>list(scope: String): Seq</b> -> Lists secret metadata for secrets within a scope<br /><b>listScopes: Seq</b> -> Lists secret scopes<br /><br /></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class = \"ansiout\">\nProvides utilities for leveraging secrets within notebooks.\nDatabricks documentation for more info.\n    <h3></h3><b>get(scope: String, key: String): String</b> -> Gets the string representation of a secret value with scope and key<br /><b>getBytes(scope: String, key: String): byte[]</b> -> Gets the bytes representation of a secret value with scope and key<br /><b>list(scope: String): Seq</b> -> Lists secret metadata for secrets within a scope<br /><b>listScopes: Seq</b> -> Lists secret scopes<br /><br /></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.secrets.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ac89248-f0d1-48ff-8218-1fd08a39c285",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####### To establish connection between databricks and keyvault\n",
    "\n",
    "* .net/#secrets/createScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02df8881-2483-4e76-b3d8-5cec1219e05d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To view all the connections to keyvault\n",
    "dbutils.secrets.listScopes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dac1f56b-f3ff-411a-851b-d692196c2803",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# will return the secrets names\n",
    "dbutils.secrets.list(\"akvconnection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e60cde2-477c-4eee-a780-d5ccbec84ee4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To retrive the contents stored in keyvault\n",
    "dbutils.secrets.get(\"akvconnection\", \"dbpwd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "205aa6a2-46dc-4944-a51d-21eb1eaa55db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Trick to see the contents in the keyvault\n",
    "for i in dbutils.secrets.get(\"akvconnection\", \"dbpwd\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "256a30d4-cbad-4e08-af66-0ba457046517",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#L7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e525ec3-e51f-491a-ab9e-7729efbc1019",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##dbutils.widgets (Notebook parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9b1c360-91f7-4aef-8e7d-c708e46310bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\"><b>dbutils.widgets</b> provides utilities for working with notebook widgets. You can create\n",
       "different types of widgets and get their bound value.\n",
       "\n",
       "For more info about a method, use <b>dbutils.widgets.help(\"methodName\")</b>.\n",
       "    <h3></h3><b>combobox(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a combobox input widget with a given name, default value and choices<br /><b>dropdown(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a dropdown input widget a with given name, default value and choices<br /><b>get(name: String): String</b> -> Retrieves current value of an input widget<br /><b>getArgument(name: String, optional: String): String</b> -> (DEPRECATED) Equivalent to get<br /><b>multiselect(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a multiselect input widget with a given name, default value and choices<br /><b>remove(name: String): void</b> -> Removes an input widget from the notebook<br /><b>removeAll: void</b> -> Removes all widgets in the notebook<br /><b>text(name: String, defaultValue: String, label: String): void</b> -> Creates a text input widget with a given name and default value<br /><br /></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class = \"ansiout\"><b>dbutils.widgets</b> provides utilities for working with notebook widgets. You can create\ndifferent types of widgets and get their bound value.\n\nFor more info about a method, use <b>dbutils.widgets.help(\"methodName\")</b>.\n    <h3></h3><b>combobox(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a combobox input widget with a given name, default value and choices<br /><b>dropdown(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a dropdown input widget a with given name, default value and choices<br /><b>get(name: String): String</b> -> Retrieves current value of an input widget<br /><b>getArgument(name: String, optional: String): String</b> -> (DEPRECATED) Equivalent to get<br /><b>multiselect(name: String, defaultValue: String, choices: Seq, label: String): void</b> -> Creates a multiselect input widget with a given name, default value and choices<br /><b>remove(name: String): void</b> -> Removes an input widget from the notebook<br /><b>removeAll: void</b> -> Removes all widgets in the notebook<br /><b>text(name: String, defaultValue: String, label: String): void</b> -> Creates a text input widget with a given name and default value<br /><br /></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.widgets.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "497e59f1-8f37-466d-bbaa-83b11f27a297",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a notebook parameter\n",
    "dbutils.widgets.text(\"load_type\", \"adhoc-load\")\n",
    "dbutils.widgets.text(\"load_date\", \"2024/01/01\")\n",
    "dbutils.widgets.text(\"meta_loc\", \"/mnt/global/india/landing/cust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c203fcbf-54c0-44dd-8190-9ec3505cc542",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Gives the value within the notebook parameter\n",
    "dbutils.widgets.get(\"load_type\")\n",
    "\n",
    "ltype = dbutils.widgets.get(\"load_type\")\n",
    "ldate = dbutils.widgets.get(\"load_date\")\n",
    "metaloc = dbutils.widgets.get(\"meta_loc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "066857ad-98f1-468b-86d8-01236a1f47eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incremental-load\n2024/01/01\n/mnt/global/india/landing/cust\n"
     ]
    }
   ],
   "source": [
    "print(ltype)\n",
    "print(ldate)\n",
    "print(metaloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ca9235c-7f85-43c3-b14b-976947280351",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove a notebook parameter\n",
    "dbutils.widgets.remove(\"meta_loc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee928443-6882-4560-9cdd-374447c809be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Removes all the notebook parameters\n",
    "dbutils.widgets.removeAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8686b52-31c6-45c8-9d3f-b954a9a45128",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/02/04\n"
     ]
    }
   ],
   "source": [
    "# Only a single value can be selected from the dropdown at a time. Default value must be included in choices\n",
    "dbutils.widgets.dropdown('loaddates1', '2023/02/01',['2023/02/01', '2023/02/02','2023/02/03','2023/02/04','2023/02/05'])\n",
    "ldates1 = dbutils.widgets.get('loaddates1')\n",
    "print(ldates1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49cb94ff-2284-4e3b-a4b1-a8bf11ba8909",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/02/01,2023/02/02,2023/02/10\n"
     ]
    }
   ],
   "source": [
    "# Can select multiple values at a time\n",
    "dbutils.widgets.multiselect('loaddates2', '2023/02/01',['2023/02/01', '2023/02/10', '2023/02/02','2023/02/03','2023/02/04','2023/02/05'])\n",
    "ldates2 = dbutils.widgets.get('loaddates2')\n",
    "print(ldates2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55da1a2d-5255-47ab-9a35-22ebdb423465",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/02/05\n"
     ]
    }
   ],
   "source": [
    "# Only a single value can be selected from the dropdown at a time. Default value must not be included in choices\n",
    "dbutils.widgets.combobox('loaddates', '2023/02/01',['2023/02/02','2023/02/03','2023/02/04','2023/02/05'])\n",
    "ldates = dbutils.widgets.get('loaddates')\n",
    "print(ldates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ea816b8-9f0e-4089-8e6f-2efed0bcab67",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#dbutils.notebook (Execute or terminate the another notebook from current notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d13a01df-0607-45b4-96ca-2f5359bbfcee",
     "showTitle": true,
     "title": "Way1"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for executing the notebook!\n"
     ]
    }
   ],
   "source": [
    "%run /databrickscomplete/Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb2f553e-a1b6-4a47-bbbb-e9b091e502e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n200\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6b04d4e-c438-4e5f-b364-9082a65de356",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for executing the notebook!\n"
     ]
    }
   ],
   "source": [
    "%run /databrickscomplete/Demo $pa=100 $pb=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d4a0608-8b4e-4f38-b28d-a274c965c63c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n400\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "337cc8c4-15f1-4cdb-bb35-bf4e2e9d0bb1",
     "showTitle": true,
     "title": "Way2"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.run(\"/databrickscomplete/Demo\", 10000, {\"pa\":200, \"pb\":400})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b5edeb8-30cf-4df6-acc5-a5c7c29db44c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if a-b!=0:\n",
    "    dbutils.notebook.exit(\"Record count is not matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70f429cd-6fc0-44d8-8bbc-6466b01c930f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#L8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d89eef19-a6e3-4ea5-97a7-e70f05a1be05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "* <span style=\"background-color: #ff0000\">The mount point is an workspace level connection.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4485c8ca-8025-4a98-a526-fa0eb3fa1e58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Mount bolb storage using Access Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee47ee64-7615-405a-84b6-fa5c6def6826",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: True"
     ]
    }
   ],
   "source": [
    "# Creating mount point to blob storage container using Access key\n",
    "dbutils.fs.mount(\n",
    "  source = \"wasbs://global@blobstorage01132023.blob.core.windows.net\",\n",
    "  mount_point = \"/mnt/global\",\n",
    "  extra_configs = {\"fs.azure.account.key.blobstorage01132023.blob.core.windows.net\":\"qMb4/lCDPXQwsFCTrFgZSYbDHn8u/XpRQGiVEVYf2kKwCuZBQX8V7aalEU0+iQCi6c75++yZZee9+ASt4S0FwQ==\"}) # Blob storage Accesskey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9502593-9e0e-4dc6-980d-7eaadc14cb0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n|    Name|Age|Gender|\n+--------+---+------+\n|  Kishan| 24|  Male|\n|   Kumar| 15|  Male|\n|   Reddy| 45|  Male|\n|Thamatam| 23|  Male|\n| Venkata| 67|Female|\n+--------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Read or create a dataframe with the data present in the container\n",
    "src_path = \"/mnt/global/\"\n",
    "\n",
    "df = spark.read.csv(src_path, header = True, sep = \",\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb1c381a-ddef-4e1d-856f-87ad5b84772c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+----------+\n|    Name|Age|Gender| load_date|\n+--------+---+------+----------+\n|  Kishan| 24|  Male|2024-01-13|\n|   Kumar| 15|  Male|2024-01-13|\n|   Reddy| 45|  Male|2024-01-13|\n|Thamatam| 23|  Male|2024-01-13|\n| Venkata| 67|Female|2024-01-13|\n+--------+---+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# creating a new column and adding in the current date\n",
    "from pyspark.sql.functions import current_date\n",
    "df1 = df.withColumn(\"load_date\",current_date())\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aac6920e-9dd4-4787-acba-6a5e0f8d6e2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to the blob storage container\n",
    "tgt_path = \"/mnt/global/output/\"\n",
    "\n",
    "df1.write.csv(tgt_path, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e5621b1-1ccc-4cfb-b0fa-ac80c791b90b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#L9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9a74f7a-0775-4a96-8360-bea5807d23d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Mount Adls Gen2 storage using Access Key\n",
    "\n",
    "\n",
    "* In order to mount a adls Gen2 we need to make use of <span style=\"background-color: #ff0000\">Service Principle identity</span> using the <span style=\"background-color: #ff0000\">App Registration</span>\n",
    "\n",
    "* Service Principle - When you join a new project the orgainaztion will generate a new userid and password to login to services.\n",
    "\n",
    "* App registration - We create and manage this userid within App registraions in Azure Active Directory\n",
    "\n",
    "* We need to establish connection between the app_registration_user and the adlsgen2 within the Identity Access Management(IAM) in adle Gen2 storage account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a2c17b6-591c-4f07-b2cf-bfc679429028",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: True"
     ]
    }
   ],
   "source": [
    "# Create a mount point to adls gen2 via app registration\n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "       \"fs.azure.account.oauth2.client.id\": \"ffb9a02a-90df-46b5-b169-04056b393c37\", # App registration (Application ID)\n",
    "       \"fs.azure.account.oauth2.client.secret\": \"tOv8Q~KASxnez3T55ZVrIgv68P2tA6cwd9uwFbQ8\", # App registration --> certificates & secrets --> New client secret --> Add (Value)\n",
    "       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/423a42da-ad3f-4e69-8aec-c86c0d0620b1/oauth2/token\", # App registration --> Tenant ID\n",
    "       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n",
    "\n",
    "dbutils.fs.mount(\n",
    "source = \"abfss://global@adlsgen201142023.dfs.core.windows.net/\",\n",
    "mount_point = \"/mnt/global\",\n",
    "extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd2e3af1-b253-47ef-a8ee-fb4363d6b271",
     "showTitle": true,
     "title": "Way1"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n|    Name|Age|Gender|\n+--------+---+------+\n|  Kishan| 24|  Male|\n|   Kumar| 15|  Male|\n|   Reddy| 45|  Male|\n|Thamatam| 23|  Male|\n| Venkata| 67|Female|\n+--------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Reading the file from adls gen2 location as a dataframe\n",
    "src_path = \"/mnt/global/input/\"\n",
    "\n",
    "df = spark.read.csv(src_path, header = True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2f8d0b1-26ee-4d30-8f44-86aad9dbd884",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Writing the file to the location as a csv\n",
    "tgt_path = \"mnt/global/output/\"\n",
    "\n",
    "df.write.mode(\"overwrite\").csv(tgt_path, header = True) # overwrite the data\n",
    "df.write.mode(\"append\").csv(tgt_path, header = True) # append the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35109462-43eb-48ce-b8a9-13b35482215f",
     "showTitle": true,
     "title": "Way2 (Recommended)"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n|    Name|Age|Gender|\n+--------+---+------+\n|  Kishan| 24|  Male|\n|   Kumar| 15|  Male|\n|   Reddy| 45|  Male|\n|Thamatam| 23|  Male|\n| Venkata| 67|Female|\n+--------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Reading the file from adls gen2 location as a dataframe\n",
    "src_path = \"/mnt/global/input/\"\n",
    "\n",
    "df1 = spark.read.format(\"csv\").option(\"header\",True).load(src_path)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b201a7b9-c52c-4830-b9e2-360eb7a9d81e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Writing the file to the location as a csv\n",
    "tgt_path = \"mnt/global/output/\"\n",
    "\n",
    "df1.write.mode(\"overwrite\").format(\"csv\").option(\"header\", True).save(tgt_path)\n",
    "df1.write.mode(\"append\").format(\"csv\").option(\"header\", True).save(tgt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "220b4a8d-e58e-44a8-84a3-5431e8b67bde",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#L10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4506aca6-f4ac-4427-b996-5cb1a2a677f5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "* <span style=\"background-color: #ff0000\">The direct connection is an spark session level connection.</span>\n",
    "\n",
    "* <span style=\"background-color: #ff0000\">New spark session is created for every notebook or if you detach and reattach the spark cluster.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0d7a68c-6241-433d-b408-74f37e98b512",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Direct connection to Blob Storage (Access Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40d7eeaa-c4ec-44be-ac81-602b8efcc127",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Establishing the blob connection using access keys to the spark session\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.blob01152023.blob.core.windows.net\",\"qdX3lbktTG8F/INRH3didkwt2NSugn4RUyHd49hg3YYtQ6kL9dKvqRrPNxIlOaFd3TmNHbOW5fzk+AStbrG7Lw==\") # Blob storage access key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d20c849-e1be-408b-adb9-00dd2b06e720",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n|    Name|Age|Gender|\n+--------+---+------+\n|  Kishan| 24|  Male|\n|   Kumar| 15|  Male|\n|   Reddy| 45|  Male|\n|Thamatam| 23|  Male|\n| Venkata| 67|Female|\n+--------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Reading the file from blob location as a dataframe\n",
    "src_path = \"wasbs://global@blob01152023.blob.core.windows.net/input/\"\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"header\", True).load(src_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f2c2403-90ad-4074-92f8-45d63fdc2110",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Writing the file to the location as a csv\n",
    "tgt_path = \"wasbs://global@blob01152023.blob.core.windows.net/output/\"\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"csv\").option(\"header\", True).save(tgt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "609185e0-33a3-43cf-b6bd-6c8eea400a0c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Direct connection to adls Gen2 Access Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca5babf6-6af7-4725-a6ae-d974b67461c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Establishing the adlsgen2 connection using access key to the spark session\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.adlsgen201152023.dfs.core.windows.net\",\"tPPTiw7KMy0X9FUxx2Kxzg7ZqQ4YHd4jeZGApe9HF0W9g73YToCDiYdoScKzbJBI9Dz0vZxyeUH0+AStrgKERg==\") # Adlsgen2 access key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beeac684-d708-4ecc-8d22-2507d87c55fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n|    Name|Age|Gender|\n+--------+---+------+\n|  Kishan| 24|  Male|\n|   Kumar| 15|  Male|\n|   Reddy| 45|  Male|\n|Thamatam| 23|  Male|\n| Venkata| 67|Female|\n+--------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Reading the file from adls gen2 location as a dataframe\n",
    "src_path = \"abfss://global@adlsgen201152023.dfs.core.windows.net/input/\"\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"header\", True).load(src_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "500781ca-05a8-4acd-995a-465be0e81147",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Writing the file to the location as a csv\n",
    "tgt_path = \"abfss://global@adlsgen201152023.dfs.core.windows.net/output/\"\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"csv\").option(\"header\", True).save(tgt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12202240-fb11-43c5-8138-9b78667c67a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Direct Connection to adls Gen2 Service Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "613f64a9-dd74-48df-a410-aa0543385611",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Establishing the adlsgen2 connection using service principle to the spark session\n",
    "spark.conf.set(\"fs.azure.account.auth.type.adlsgen201152023.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type.adlsgen201152023.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id.adlsgen201152023.dfs.core.windows.net\", \"44f21ab5-0696-4d62-b5f9-d2c3c4d6ccf7\") # Application ID\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret.adlsgen201152023.dfs.core.windows.net\", \"mbZ8Q~glUphbC502JV~fYtEE_1VvDDm1YHvzocMq\") # App registration --> certificates & secrets --> New client secret --> Add (Value)\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.adlsgen201152023.dfs.core.windows.net\", \"https://login.microsoftonline.com/423a42da-ad3f-4e69-8aec-c86c0d0620b1/oauth2/token\") # Directory (tenant) ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad9707d8-6e40-44a9-b2d7-eb6dbaf80ad5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n|    Name|Age|Gender|\n+--------+---+------+\n|  Kishan| 24|  Male|\n|   Kumar| 15|  Male|\n|   Reddy| 45|  Male|\n|Thamatam| 23|  Male|\n| Venkata| 67|Female|\n+--------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "src_path = \"abfss://global@adlsgen201152023.dfs.core.windows.net/input/\"\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"header\", True).load(src_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9a540a0-a30a-4ace-9d48-092de1291de9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Writing the file to the location as a csv\n",
    "tgt_path = \"abfss://global@adlsgen201152023.dfs.core.windows.net/output/\"\n",
    "\n",
    "df.write.mode(\"append\").format(\"csv\").option(\"header\", True).save(tgt_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks_complete",
   "widgets": {
    "loaddates": {
     "currentValue": "2023/02/05",
     "nuid": "7e28e644-a9ed-4fad-9c2d-dac255cd2908",
     "widgetInfo": {
      "widgetType": "combobox",
      "defaultValue": "2023/02/01",
      "label": null,
      "name": "loaddates",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "2023/02/02",
        "2023/02/03",
        "2023/02/04",
        "2023/02/05"
       ]
      }
     }
    },
    "loaddates1": {
     "currentValue": "2023/02/04",
     "nuid": "13a8d584-8783-49a2-8f6c-9778166bbe5f",
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "2023/02/01",
      "label": null,
      "name": "loaddates1",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "2023/02/01",
        "2023/02/02",
        "2023/02/03",
        "2023/02/04",
        "2023/02/05"
       ]
      }
     }
    },
    "loaddates2": {
     "currentValue": "2023/02/01,2023/02/02,2023/02/10",
     "nuid": "a03f4512-ad45-439e-88f8-115581de1677",
     "widgetInfo": {
      "widgetType": "multiselect",
      "defaultValue": "2023/02/01",
      "label": null,
      "name": "loaddates2",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "2023/02/01",
        "2023/02/10",
        "2023/02/02",
        "2023/02/03",
        "2023/02/04",
        "2023/02/05"
       ]
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
